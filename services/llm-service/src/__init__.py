"""
LLM Service Package

A production-ready FastAPI wrapper around vLLM for on-premise LLM inference.

Provides:
- Text generation with streaming
- Chat completion
- Text classification
- Entity extraction
- Text summarization
- Embeddings generation
"""

__version__ = "1.0.0"
__author__ = "FlowForge Team"
